# Action Recognition in videos 
Mi **Trabajo fin de Máster** sobre el reconocimiento de acciones en los videos sobre un dominio concreto, el baile. 
En primer lugar, se entrenan dos modelos con dos approaches diferentes detallados en el paper del proyecto utilizando el dataset de Let'sDance. 
En segundo lugar, se implementa una API con dos servicios uno para cada modelo. Cada servicio recibe una url y devuelve un json con la etiqueta y la confianza del modelo.


![tools](https://github.com/pilarcode/action-recognition-in-videos/blob/master/images/tools.png)

![table 1](https://github.com/pilarcode/action-recognition-in-videos/blob/master/images/table1.png)

![table 1](https://github.com/pilarcode/action-recognition-in-videos/blob/master/images/table2.png)


![inferencia ejemplos](https://github.com/pilarcode/action-recognition-in-videos/blob/master/images/ejemplo_inferencia.png)

**References**:
Castro, D. (2018, January 23). Let’s Dance: Learning From Online Dance Videos. ArXiv.Org. https://arxiv.org/abs/1801.07388 
